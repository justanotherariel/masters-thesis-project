command:
  - python3
  - ${program}
  - ${args_no_hyphens}
method: bayes
project: Thesis
entity: a-ebersberger-tu-delft
program: train.py
name: TransformerAttentionSinkLayer | Adafactor | ETA HPO
metric:
  name: Validation/Transition Accuracy
  goal: maximize
parameters:

  model:
    value: transformer_attention_sink_layer

  model.train_sys.steps.0.epochs:
    value: 1000

  # n_trials:
  #   value: 5

  Optimizer/Scheduler Parameters
  model.train_sys.steps.0.optimizer.lr:
    distribution: log_uniform_values
    min: 1e-5
    max: 5e-3

  model.train_sys.steps.0.scheduler.decay_rate:
    distribution: uniform
    min: 0.2
    max: 0.9

  model.train_sys.steps.0.scheduler.decay_t:
    distribution: int_uniform
    min: 50
    max: 300


  # Loss Parameters
  model.train_sys.steps.0.loss.eta_loss_fn._args_.0.path:
    values:
      - src.modules.training.loss.eta_l1_loss
      - src.modules.training.loss.eta_l2_loss
      - src.modules.training.loss.eta_l_ratio_loss
      - src.modules.training.loss.eta_entropy_loss

  model.train_sys.steps.0.loss.eta_loss_fn.weight:
    distribution: uniform
    min: 0.1e-5
    max: 0.1e-1
  

  # Model parameters
  # model.train_sys.steps.0.model.d_model:
  #   values: [128, 256, 512]

  # model.train_sys.steps.0.model.n_heads:
  #   values: [4, 8, 16, 32]

  # model.train_sys.steps.0.model.n_layers:
  #   values: [1, 2, 3, 4]

  # model.train_sys.steps.0.model.d_ff:
  #   values: [256, 512, 1024]

  # model.train_sys.steps.0.model.drop_prob:
  #   distribution: uniform
  #   min: 0.05
  #   max: 0.3
