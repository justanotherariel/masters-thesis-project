command:
  - python3
  - ${program}
  - ${args_no_hyphens}
method: bayes
project: Thesis
entity: a-ebersberger-tu-delft
program: train.py
name: Transformer | attention_focus_loss
metric:
  name: Train/Transition Accuracy
  goal: maximize
parameters:

  model:
    value: transformer_extensive

  model.train_sys.steps.0.epochs:
    value: 1000

  # n_trials:
  #   value: 5

  # # Model Type
  # model.train_sys.steps.0.model.model_cls._target_:
  #   values:
  #     - src.modules.training.models.transformer.TransformerCombAction
  #     - src.modules.training.models.transformer.TransformerSepAction

  # Optimizer/Scheduler Parameters
  # model.train_sys.steps.0.optimizer.lr:
  #   distribution: log_uniform_values
  #   min: 1e-5
  #   max: 5e-3

  # model.train_sys.steps.0.scheduler.decay_rate:
  #   distribution: uniform
  #   min: 0.2
  #   max: 0.9

  # model.train_sys.steps.0.scheduler.decay_t:
  #   distribution: int_uniform
  #   min: 50
  #   max: 300


  # Loss Parameters
  model.train_sys.steps.0.loss.eta_loss_fn.factor:
    distribution: uniform
    min: 0.0
    max: 1.0
  

  # Model parameters
  # model.train_sys.steps.0.model.d_model:
  #   values: [128, 256, 512]

  # model.train_sys.steps.0.model.n_heads:
  #   values: [4, 8, 16, 32]

  # model.train_sys.steps.0.model.n_layers:
  #   values: [1, 2, 3, 4]

  # model.train_sys.steps.0.model.d_ff:
  #   values: [256, 512, 1024]

  # model.train_sys.steps.0.model.drop_prob:
  #   distribution: uniform
  #   min: 0.05
  #   max: 0.3
