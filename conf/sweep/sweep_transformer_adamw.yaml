command:
  - python3
  - ${program}
  - model=transformer_attention_sink_layer_adamw
  - ${args_no_hyphens}
method: bayes
project: Thesis
entity: a-ebersberger-tu-delft
program: train.py
name: TransformerAttentionSinkLayer | AdamW | ETA HPO
metric:
  name: Validation/Transition Accuracy
  goal: maximize
parameters:

  # n_trials:
  #   value: 5


  # Optimizer/Scheduler Parameters
  model.train_sys.steps.0.optimizer.lr:
    distribution: log_uniform_values
    min: 1e-4
    max: 0.1

  model.train_sys.steps.0.scheduler.decay_rate:
    distribution: uniform
    min: 0.50
    max: 0.95

  model.train_sys.steps.0.scheduler.decay_t:
    distribution: int_uniform
    min: 100
    max: 350


  # Loss Parameters
  model.train_sys.steps.0.loss.eta_loss_fn._args_.0.path:
    values:
      - src.modules.training.loss.eta_l1_loss
      - src.modules.training.loss.eta_l2_loss

  model.train_sys.steps.0.loss.eta_loss_fn.weight:
    distribution: log_uniform_values
    min: 0.1e-5
    max: 0.5e-2
  

  # Model parameters
  # model.train_sys.steps.0.model.d_model:
  #   values: [128, 256, 512]

  # model.train_sys.steps.0.model.n_heads:
  #   values: [4, 8, 16, 32]

  # model.train_sys.steps.0.model.n_layers:
  #   values: [1, 2, 3, 4]

  # model.train_sys.steps.0.model.d_ff:
  #   values: [256, 512, 1024]

  # model.train_sys.steps.0.model.drop_prob:
  #   distribution: uniform
  #   min: 0.05
  #   max: 0.3
